{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "441a56b9-e653-44d0-b120-da727ba0fbfa",
   "metadata": {},
   "source": [
    "# Hackathon: Predicting Book Price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f418c397-8587-44e8-b541-c54d16cbe760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "#Import test and train data \n",
    "test_data = pd.read_excel(r'Data_Test.xlsx')\n",
    "train_data = pd.read_excel(r'Data_Train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15963d7b-fff2-4cef-8a3c-577564455a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1560 entries, 0 to 1559\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Title         1560 non-null   object\n",
      " 1   Author        1560 non-null   object\n",
      " 2   Edition       1560 non-null   object\n",
      " 3   Reviews       1560 non-null   object\n",
      " 4   Ratings       1560 non-null   object\n",
      " 5   Synopsis      1560 non-null   object\n",
      " 6   Genre         1560 non-null   object\n",
      " 7   BookCategory  1560 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 97.6+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18dca152-f757-4217-9976-987b5b3ee3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Edition</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Genre</th>\n",
       "      <th>BookCategory</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Prisoner's Gold (The Hunters 3)</td>\n",
       "      <td>Chris Kuzneski</td>\n",
       "      <td>Paperback,– 10 Mar 2016</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>8 customer reviews</td>\n",
       "      <td>THE HUNTERS return in their third brilliant no...</td>\n",
       "      <td>Action &amp; Adventure (Books)</td>\n",
       "      <td>Action &amp; Adventure</td>\n",
       "      <td>220.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guru Dutt: A Tragedy in Three Acts</td>\n",
       "      <td>Arun Khopkar</td>\n",
       "      <td>Paperback,– 7 Nov 2012</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>14 customer reviews</td>\n",
       "      <td>A layered portrait of a troubled genius for wh...</td>\n",
       "      <td>Cinema &amp; Broadcast (Books)</td>\n",
       "      <td>Biographies, Diaries &amp; True Accounts</td>\n",
       "      <td>202.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leviathan (Penguin Classics)</td>\n",
       "      <td>Thomas Hobbes</td>\n",
       "      <td>Paperback,– 25 Feb 1982</td>\n",
       "      <td>4.8 out of 5 stars</td>\n",
       "      <td>6 customer reviews</td>\n",
       "      <td>\"During the time men live without a common Pow...</td>\n",
       "      <td>International Relations</td>\n",
       "      <td>Humour</td>\n",
       "      <td>299.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Pocket Full of Rye (Miss Marple)</td>\n",
       "      <td>Agatha Christie</td>\n",
       "      <td>Paperback,– 5 Oct 2017</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>13 customer reviews</td>\n",
       "      <td>A handful of grain is found in the pocket of a...</td>\n",
       "      <td>Contemporary Fiction (Books)</td>\n",
       "      <td>Crime, Thriller &amp; Mystery</td>\n",
       "      <td>180.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIFE 70 Years of Extraordinary Photography</td>\n",
       "      <td>Editors of Life</td>\n",
       "      <td>Hardcover,– 10 Oct 2006</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>1 customer review</td>\n",
       "      <td>For seven decades, \"Life\" has been thrilling t...</td>\n",
       "      <td>Photography Textbooks</td>\n",
       "      <td>Arts, Film &amp; Photography</td>\n",
       "      <td>965.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Title           Author  \\\n",
       "0         The Prisoner's Gold (The Hunters 3)   Chris Kuzneski   \n",
       "1          Guru Dutt: A Tragedy in Three Acts     Arun Khopkar   \n",
       "2                Leviathan (Penguin Classics)    Thomas Hobbes   \n",
       "3          A Pocket Full of Rye (Miss Marple)  Agatha Christie   \n",
       "4  LIFE 70 Years of Extraordinary Photography  Editors of Life   \n",
       "\n",
       "                   Edition             Reviews              Ratings  \\\n",
       "0  Paperback,– 10 Mar 2016  4.0 out of 5 stars   8 customer reviews   \n",
       "1   Paperback,– 7 Nov 2012  3.9 out of 5 stars  14 customer reviews   \n",
       "2  Paperback,– 25 Feb 1982  4.8 out of 5 stars   6 customer reviews   \n",
       "3   Paperback,– 5 Oct 2017  4.1 out of 5 stars  13 customer reviews   \n",
       "4  Hardcover,– 10 Oct 2006  5.0 out of 5 stars    1 customer review   \n",
       "\n",
       "                                            Synopsis  \\\n",
       "0  THE HUNTERS return in their third brilliant no...   \n",
       "1  A layered portrait of a troubled genius for wh...   \n",
       "2  \"During the time men live without a common Pow...   \n",
       "3  A handful of grain is found in the pocket of a...   \n",
       "4  For seven decades, \"Life\" has been thrilling t...   \n",
       "\n",
       "                          Genre                          BookCategory   Price  \n",
       "0    Action & Adventure (Books)                    Action & Adventure  220.00  \n",
       "1    Cinema & Broadcast (Books)  Biographies, Diaries & True Accounts  202.93  \n",
       "2       International Relations                                Humour  299.00  \n",
       "3  Contemporary Fiction (Books)             Crime, Thriller & Mystery  180.00  \n",
       "4         Photography Textbooks              Arts, Film & Photography  965.62  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loodking at top 5 rows \n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89a4a8d0-765f-4ff1-b8d1-955870f65780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6237"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb32d097-ff7c-44fe-9649-3ca1d65b8508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title 1521\n",
      "Author 1224\n",
      "Edition 1259\n",
      "Reviews 30\n",
      "Ratings 163\n",
      "Synopsis 1519\n",
      "Genre 225\n",
      "BookCategory 11\n"
     ]
    }
   ],
   "source": [
    "#LOOKING At all unique values for \n",
    "for i in list(test_data.columns.unique()):\n",
    "    print(i, len(test_data[str(i)].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c95d22-27bf-4f14-9798-d95e4eee9900",
   "metadata": {},
   "source": [
    "# Cleaning / Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2581a50-b36c-4a8d-9c96-412ae2eb8808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking to see if their is a larger range for 5 star reviews\n",
    "train_data['Reviews'].str.split(\" \" , expand = True)[3].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fed3a6c1-7f48-472c-98b5-47963db58266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "def cleaning(df):\n",
    "    df['Reviews'] = df['Reviews'].str.split(\" \" , expand = True)[0].astype(float)\n",
    "    df['Edition'] = df['Edition'].str.split(\",\" , expand = True)[0]   #[3].unique()\n",
    "    df['Ratings'] = pd.DataFrame(df['Ratings'].str.split(\" \", expand=True)[0].str.replace(',', '')).astype(int)\n",
    "    # Define a function to get the polarity of a text\n",
    "    def get_polarity(text):\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "    \n",
    "    # Getting polarity score as a feature - method is to get a more granular look at the message itselgf \n",
    "    df['Synopsis_polarity'] = df['Synopsis'].apply(get_polarity).astype(float)\n",
    "    df = df.drop('Synopsis', axis=1)\n",
    "    df = df.drop('Genre', axis=1)  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "612c6267-002e-40e8-94e8-52d013e1def7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = cleaning(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d92818-374d-4667-9659-4137193e3129",
   "metadata": {},
   "source": [
    "# Identifying Feature Datatypes:\n",
    "\n",
    "    - Title ( Qualitative )\n",
    "    - Author ( Qualitative ) \n",
    "    - Edition (Qualitative )\n",
    "    - Reviews (Quantitative continuous)\n",
    "    - Rating ( Quantitative discrete)\n",
    "    - Genre ( Qualitative Categorica) \n",
    "    - BookCategory ( Qualitative Categorical ) \n",
    "    - Price ( Quantitative Continous )\n",
    "    - Synopsis_polarity ( Quantitative Continuous ? )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "624ed0c5-85c8-404a-8411-c9616625bda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6237 entries, 0 to 6236\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Title              6237 non-null   object \n",
      " 1   Author             6237 non-null   object \n",
      " 2   Edition            6237 non-null   object \n",
      " 3   Reviews            6237 non-null   float64\n",
      " 4   Ratings            6237 non-null   int64  \n",
      " 5   BookCategory       6237 non-null   object \n",
      " 6   Price              6237 non-null   float64\n",
      " 7   Synopsis_polarity  6237 non-null   float64\n",
      "dtypes: float64(3), int64(1), object(4)\n",
      "memory usage: 389.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbb6bb93-177c-4cf9-985a-2da2abc49f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Edition</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>BookCategory</th>\n",
       "      <th>Price</th>\n",
       "      <th>Synopsis_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Prisoner's Gold (The Hunters 3)</td>\n",
       "      <td>Chris Kuzneski</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Action &amp; Adventure</td>\n",
       "      <td>220.00</td>\n",
       "      <td>0.208800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guru Dutt: A Tragedy in Three Acts</td>\n",
       "      <td>Arun Khopkar</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>3.9</td>\n",
       "      <td>14</td>\n",
       "      <td>Biographies, Diaries &amp; True Accounts</td>\n",
       "      <td>202.93</td>\n",
       "      <td>0.183471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leviathan (Penguin Classics)</td>\n",
       "      <td>Thomas Hobbes</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6</td>\n",
       "      <td>Humour</td>\n",
       "      <td>299.00</td>\n",
       "      <td>0.191075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Pocket Full of Rye (Miss Marple)</td>\n",
       "      <td>Agatha Christie</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.1</td>\n",
       "      <td>13</td>\n",
       "      <td>Crime, Thriller &amp; Mystery</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIFE 70 Years of Extraordinary Photography</td>\n",
       "      <td>Editors of Life</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Arts, Film &amp; Photography</td>\n",
       "      <td>965.62</td>\n",
       "      <td>0.356250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Title           Author    Edition  \\\n",
       "0         The Prisoner's Gold (The Hunters 3)   Chris Kuzneski  Paperback   \n",
       "1          Guru Dutt: A Tragedy in Three Acts     Arun Khopkar  Paperback   \n",
       "2                Leviathan (Penguin Classics)    Thomas Hobbes  Paperback   \n",
       "3          A Pocket Full of Rye (Miss Marple)  Agatha Christie  Paperback   \n",
       "4  LIFE 70 Years of Extraordinary Photography  Editors of Life  Hardcover   \n",
       "\n",
       "   Reviews  Ratings                          BookCategory   Price  \\\n",
       "0      4.0        8                    Action & Adventure  220.00   \n",
       "1      3.9       14  Biographies, Diaries & True Accounts  202.93   \n",
       "2      4.8        6                                Humour  299.00   \n",
       "3      4.1       13             Crime, Thriller & Mystery  180.00   \n",
       "4      5.0        1              Arts, Film & Photography  965.62   \n",
       "\n",
       "   Synopsis_polarity  \n",
       "0           0.208800  \n",
       "1           0.183471  \n",
       "2           0.191075  \n",
       "3           0.100000  \n",
       "4           0.356250  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e422e919-f677-43b5-a8a2-285fba40c701",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd86c561-0377-46e7-ab73-4b3a50b1ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):    \n",
    "    #book_cat = pd.get_dummies(df['BookCategory'], prefix='BookCategory')\n",
    "    #model_df = pd.concat([df, book_cat], axis=1)\n",
    "    #Edition = pd.get_dummies(df['Edition'], prefix='Edition')\n",
    "    #model_df = pd.concat([df, Edition], axis=1)   \n",
    "    df = df.drop(['Title','Author'], axis=1)\n",
    "    #model_df['Edition'] = model_df.Edition.map({'Paperback': 0 , 'Hardcover' : 1})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41bfc1d6-fce7-4e02-b760-d57f9a3bf0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = preprocessing(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "230b7a58-5c63-479e-bfee-55b115c5cc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Edition</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Genre</th>\n",
       "      <th>BookCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Complete Sherlock Holmes: 2 Boxes sets</td>\n",
       "      <td>Sir Arthur Conan Doyle</td>\n",
       "      <td>Mass Market Paperback,– 1 Oct 1986</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>960 customer reviews</td>\n",
       "      <td>A collection of entire body of work of the She...</td>\n",
       "      <td>Short Stories (Books)</td>\n",
       "      <td>Crime, Thriller &amp; Mystery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Learn Docker - Fundamentals of Docker 18.x: Ev...</td>\n",
       "      <td>Gabriel N. Schenker</td>\n",
       "      <td>Paperback,– Import, 26 Apr 2018</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>1 customer review</td>\n",
       "      <td>Enhance your software deployment workflow usin...</td>\n",
       "      <td>Operating Systems Textbooks</td>\n",
       "      <td>Computing, Internet &amp; Digital Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big Girl</td>\n",
       "      <td>Danielle Steel</td>\n",
       "      <td>Paperback,– 17 Mar 2011</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>4 customer reviews</td>\n",
       "      <td>'Watch out, world. Here I come!'\\nFor Victoria...</td>\n",
       "      <td>Romance (Books)</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Think Python: How to Think Like a Computer Sci...</td>\n",
       "      <td>Allen B. Downey</td>\n",
       "      <td>Paperback,– 2016</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>11 customer reviews</td>\n",
       "      <td>If you want to learn how to program, working w...</td>\n",
       "      <td>Programming &amp; Software Development (Books)</td>\n",
       "      <td>Computing, Internet &amp; Digital Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oxford Word Skills: Advanced - Idioms &amp; Phrasa...</td>\n",
       "      <td>Redman Gairns</td>\n",
       "      <td>Paperback,– 26 Dec 2011</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>9 customer reviews</td>\n",
       "      <td>Learn and practise the verbs, prepositions and...</td>\n",
       "      <td>Linguistics (Books)</td>\n",
       "      <td>Language, Linguistics &amp; Writing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>100 Things Every Designer Needs to Know About ...</td>\n",
       "      <td>Susan Weinschenk</td>\n",
       "      <td>Paperback,– 14 Apr 2011</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>4 customer reviews</td>\n",
       "      <td>We design to elicit responses from people. We ...</td>\n",
       "      <td>Design</td>\n",
       "      <td>Computing, Internet &amp; Digital Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>Modern Letter Writing Course: Personal, Busine...</td>\n",
       "      <td>ARUN SAGAR</td>\n",
       "      <td>Paperback,– 8 May 2013</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "      <td>13 customer reviews</td>\n",
       "      <td>A 30-day course to write simple, sharp and att...</td>\n",
       "      <td>Children's Reference (Books)</td>\n",
       "      <td>Biographies, Diaries &amp; True Accounts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>The Kite Runner Graphic Novel</td>\n",
       "      <td>Khaled Hosseini</td>\n",
       "      <td>Paperback,– 6 Sep 2011</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>5 customer reviews</td>\n",
       "      <td>The perennial bestseller-now available as a se...</td>\n",
       "      <td>Humour (Books)</td>\n",
       "      <td>Humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>Panzer Leader (Penguin World War II Collection)</td>\n",
       "      <td>Heinz Guderian</td>\n",
       "      <td>Paperback,– 22 Sep 2009</td>\n",
       "      <td>3.5 out of 5 stars</td>\n",
       "      <td>3 customer reviews</td>\n",
       "      <td>Heinz Guderian - master of the Blitzkrieg and ...</td>\n",
       "      <td>United States History</td>\n",
       "      <td>Biographies, Diaries &amp; True Accounts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>Complete Spanish Step-by-Step</td>\n",
       "      <td>Barbara Bregstein</td>\n",
       "      <td>Paperback,– 16 Sep 2016</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>2 customer reviews</td>\n",
       "      <td>Learn Spanish with the most convenient and eff...</td>\n",
       "      <td>Dictionaries</td>\n",
       "      <td>Language, Linguistics &amp; Writing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1560 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  \\\n",
       "0            The Complete Sherlock Holmes: 2 Boxes sets   \n",
       "1     Learn Docker - Fundamentals of Docker 18.x: Ev...   \n",
       "2                                              Big Girl   \n",
       "3     Think Python: How to Think Like a Computer Sci...   \n",
       "4     Oxford Word Skills: Advanced - Idioms & Phrasa...   \n",
       "...                                                 ...   \n",
       "1555  100 Things Every Designer Needs to Know About ...   \n",
       "1556  Modern Letter Writing Course: Personal, Busine...   \n",
       "1557                      The Kite Runner Graphic Novel   \n",
       "1558    Panzer Leader (Penguin World War II Collection)   \n",
       "1559                      Complete Spanish Step-by-Step   \n",
       "\n",
       "                      Author                             Edition  \\\n",
       "0     Sir Arthur Conan Doyle  Mass Market Paperback,– 1 Oct 1986   \n",
       "1        Gabriel N. Schenker     Paperback,– Import, 26 Apr 2018   \n",
       "2             Danielle Steel             Paperback,– 17 Mar 2011   \n",
       "3            Allen B. Downey                    Paperback,– 2016   \n",
       "4              Redman Gairns             Paperback,– 26 Dec 2011   \n",
       "...                      ...                                 ...   \n",
       "1555        Susan Weinschenk             Paperback,– 14 Apr 2011   \n",
       "1556              ARUN SAGAR              Paperback,– 8 May 2013   \n",
       "1557         Khaled Hosseini              Paperback,– 6 Sep 2011   \n",
       "1558          Heinz Guderian             Paperback,– 22 Sep 2009   \n",
       "1559       Barbara Bregstein             Paperback,– 16 Sep 2016   \n",
       "\n",
       "                 Reviews               Ratings  \\\n",
       "0     4.4 out of 5 stars  960 customer reviews   \n",
       "1     5.0 out of 5 stars     1 customer review   \n",
       "2     5.0 out of 5 stars    4 customer reviews   \n",
       "3     4.1 out of 5 stars   11 customer reviews   \n",
       "4     4.4 out of 5 stars    9 customer reviews   \n",
       "...                  ...                   ...   \n",
       "1555  5.0 out of 5 stars    4 customer reviews   \n",
       "1556  3.6 out of 5 stars   13 customer reviews   \n",
       "1557  4.0 out of 5 stars    5 customer reviews   \n",
       "1558  3.5 out of 5 stars    3 customer reviews   \n",
       "1559  4.5 out of 5 stars    2 customer reviews   \n",
       "\n",
       "                                               Synopsis  \\\n",
       "0     A collection of entire body of work of the She...   \n",
       "1     Enhance your software deployment workflow usin...   \n",
       "2     'Watch out, world. Here I come!'\\nFor Victoria...   \n",
       "3     If you want to learn how to program, working w...   \n",
       "4     Learn and practise the verbs, prepositions and...   \n",
       "...                                                 ...   \n",
       "1555  We design to elicit responses from people. We ...   \n",
       "1556  A 30-day course to write simple, sharp and att...   \n",
       "1557  The perennial bestseller-now available as a se...   \n",
       "1558  Heinz Guderian - master of the Blitzkrieg and ...   \n",
       "1559  Learn Spanish with the most convenient and eff...   \n",
       "\n",
       "                                           Genre  \\\n",
       "0                          Short Stories (Books)   \n",
       "1                    Operating Systems Textbooks   \n",
       "2                                Romance (Books)   \n",
       "3     Programming & Software Development (Books)   \n",
       "4                            Linguistics (Books)   \n",
       "...                                          ...   \n",
       "1555                                      Design   \n",
       "1556                Children's Reference (Books)   \n",
       "1557                              Humour (Books)   \n",
       "1558                       United States History   \n",
       "1559                                Dictionaries   \n",
       "\n",
       "                              BookCategory  \n",
       "0                Crime, Thriller & Mystery  \n",
       "1      Computing, Internet & Digital Media  \n",
       "2                                  Romance  \n",
       "3      Computing, Internet & Digital Media  \n",
       "4          Language, Linguistics & Writing  \n",
       "...                                    ...  \n",
       "1555   Computing, Internet & Digital Media  \n",
       "1556  Biographies, Diaries & True Accounts  \n",
       "1557                                Humour  \n",
       "1558  Biographies, Diaries & True Accounts  \n",
       "1559       Language, Linguistics & Writing  \n",
       "\n",
       "[1560 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fd80c8-3c17-4cbb-b1f1-7cb3531cbc55",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b092b43-8930-47c1-8f0a-62741ca24db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regression_models(df, target_column, test_size=0.2, random_state=42):\n",
    "    # Split data into features and target\n",
    "    \n",
    "    features = df.drop(target_column, axis=1)\n",
    "    target = df[target_column]\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Regression models being tested\n",
    "    models = [LinearRegression(), Ridge(), Lasso(), ElasticNet(), \n",
    "              DecisionTreeRegressor(), RandomForestRegressor(), \n",
    "              GradientBoostingRegressor(), KNeighborsRegressor(), SVR()]\n",
    "\n",
    "    # Loop through each model and evaluate its performance using multiple metrics\n",
    "    metrics = {'MSE': mean_squared_error, 'RMSE': lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), \n",
    "               'MAE': mean_absolute_error, 'R2': r2_score}\n",
    "    model_metrics = []\n",
    "    for model in models:\n",
    "        mse_scores = -cross_val_score(model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "        model_metrics.append({'Model': str(model), 'MSE': mse_scores.mean(), \n",
    "                              'RMSE': metrics['RMSE'](y_train, model.fit(X_train, y_train).predict(X_train)),\n",
    "                              'MAE': metrics['MAE'](y_train, model.fit(X_train, y_train).predict(X_train)),\n",
    "                              'R2': metrics['R2'](y_train, model.fit(X_train, y_train).predict(X_train))})\n",
    "\n",
    "    return model_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "642a320e-1bd7-4ec2-b70b-ea58b5b07f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "      <th>Synopsis_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>220.00</td>\n",
       "      <td>0.208800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.9</td>\n",
       "      <td>14</td>\n",
       "      <td>202.93</td>\n",
       "      <td>0.183471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.8</td>\n",
       "      <td>6</td>\n",
       "      <td>299.00</td>\n",
       "      <td>0.191075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.1</td>\n",
       "      <td>13</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>965.62</td>\n",
       "      <td>0.356250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6232</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>322.00</td>\n",
       "      <td>0.058490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6233</th>\n",
       "      <td>3.3</td>\n",
       "      <td>9</td>\n",
       "      <td>421.00</td>\n",
       "      <td>0.065029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6234</th>\n",
       "      <td>3.8</td>\n",
       "      <td>3</td>\n",
       "      <td>399.00</td>\n",
       "      <td>0.367284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6235</th>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>319.00</td>\n",
       "      <td>0.185119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6236</th>\n",
       "      <td>3.9</td>\n",
       "      <td>2</td>\n",
       "      <td>452.00</td>\n",
       "      <td>-0.011905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6237 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Reviews  Ratings   Price  Synopsis_polarity\n",
       "0         4.0        8  220.00           0.208800\n",
       "1         3.9       14  202.93           0.183471\n",
       "2         4.8        6  299.00           0.191075\n",
       "3         4.1       13  180.00           0.100000\n",
       "4         5.0        1  965.62           0.356250\n",
       "...       ...      ...     ...                ...\n",
       "6232      5.0        2  322.00           0.058490\n",
       "6233      3.3        9  421.00           0.065029\n",
       "6234      3.8        3  399.00           0.367284\n",
       "6235      3.5        4  319.00           0.185119\n",
       "6236      3.9        2  452.00          -0.011905\n",
       "\n",
       "[6237 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2f11014c-0b40-4976-b078-fe48a369dbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tylerbrown/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tylerbrown/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tylerbrown/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py\", line 662, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"/Users/tylerbrown/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/Users/tylerbrown/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 964, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"/Users/tylerbrown/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 746, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"/Users/tylerbrown/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\", line 2070, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'Private India'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tylerbrown/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tylerbrown/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py\", line 662, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"/Users/tylerbrown/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/Users/tylerbrown/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 964, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"/Users/tylerbrown/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 746, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"/Users/tylerbrown/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\", line 2070, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'How to be an Explorer of the World'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'How to be an Explorer of the World'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [122]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_regression_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [90]\u001b[0m, in \u001b[0;36mevaluate_regression_models\u001b[0;34m(df, target_column, test_size, random_state)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m     20\u001b[0m     mse_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mcross_val_score(model, X_train, y_train, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     21\u001b[0m     model_metrics\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(model), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSE\u001b[39m\u001b[38;5;124m'\u001b[39m: mse_scores\u001b[38;5;241m.\u001b[39mmean(), \n\u001b[0;32m---> 22\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m: metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m](y_train, \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_train)),\n\u001b[1;32m     23\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m'\u001b[39m: metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m'\u001b[39m](y_train, model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\u001b[38;5;241m.\u001b[39mpredict(X_train)),\n\u001b[1;32m     24\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR2\u001b[39m\u001b[38;5;124m'\u001b[39m: metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR2\u001b[39m\u001b[38;5;124m'\u001b[39m](y_train, model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\u001b[38;5;241m.\u001b[39mpredict(X_train))})\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_metrics\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:662\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    658\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[1;32m    660\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 662\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    664\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    667\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 581\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 964\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric)\n\u001b[1;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'How to be an Explorer of the World'"
     ]
    }
   ],
   "source": [
    "results = evaluate_regression_models(train_data, 'Price')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce87aaf-0a71-44e3-b7bf-9ed6fe54c223",
   "metadata": {},
   "source": [
    "# Models that Will Be Considered: \n",
    "\n",
    "    - Random Forest Regressor ( decent mean squared error, good RMSE, 2nd best mean absolute error/ R2) - overall has best all around metrics \n",
    "    -  Decision tree has a terrible mean squared error, but is the best fit for the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c679130c-ee9b-4199-9a35-e5aa39e3ec6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>454433.517580</td>\n",
       "      <td>643.040138</td>\n",
       "      <td>343.257296</td>\n",
       "      <td>0.152024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge()</td>\n",
       "      <td>453829.365723</td>\n",
       "      <td>649.700072</td>\n",
       "      <td>345.406985</td>\n",
       "      <td>0.134369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso()</td>\n",
       "      <td>453165.406105</td>\n",
       "      <td>647.287427</td>\n",
       "      <td>345.091254</td>\n",
       "      <td>0.140786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet()</td>\n",
       "      <td>469144.079739</td>\n",
       "      <td>683.704598</td>\n",
       "      <td>356.288652</td>\n",
       "      <td>0.041385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "      <td>735654.224040</td>\n",
       "      <td>99.303073</td>\n",
       "      <td>10.071208</td>\n",
       "      <td>0.979778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor()</td>\n",
       "      <td>469223.870806</td>\n",
       "      <td>262.045002</td>\n",
       "      <td>129.618907</td>\n",
       "      <td>0.852430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor()</td>\n",
       "      <td>438097.121828</td>\n",
       "      <td>588.743746</td>\n",
       "      <td>312.099357</td>\n",
       "      <td>0.289180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsRegressor()</td>\n",
       "      <td>476598.800116</td>\n",
       "      <td>565.631551</td>\n",
       "      <td>291.472692</td>\n",
       "      <td>0.343893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVR()</td>\n",
       "      <td>518019.665737</td>\n",
       "      <td>719.222596</td>\n",
       "      <td>313.322187</td>\n",
       "      <td>-0.060801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model            MSE        RMSE         MAE  \\\n",
       "0           LinearRegression()  454433.517580  643.040138  343.257296   \n",
       "1                      Ridge()  453829.365723  649.700072  345.406985   \n",
       "2                      Lasso()  453165.406105  647.287427  345.091254   \n",
       "3                 ElasticNet()  469144.079739  683.704598  356.288652   \n",
       "4      DecisionTreeRegressor()  735654.224040   99.303073   10.071208   \n",
       "5      RandomForestRegressor()  469223.870806  262.045002  129.618907   \n",
       "6  GradientBoostingRegressor()  438097.121828  588.743746  312.099357   \n",
       "7        KNeighborsRegressor()  476598.800116  565.631551  291.472692   \n",
       "8                        SVR()  518019.665737  719.222596  313.322187   \n",
       "\n",
       "         R2  \n",
       "0  0.152024  \n",
       "1  0.134369  \n",
       "2  0.140786  \n",
       "3  0.041385  \n",
       "4  0.979778  \n",
       "5  0.852430  \n",
       "6  0.289180  \n",
       "7  0.343893  \n",
       "8 -0.060801  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46789de2-c16a-40c2-ac46-dd4a89af6086",
   "metadata": {},
   "source": [
    "# Creating model - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9aa2690-b5a4-4049-ba11-31b87c6bfcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model features and target\n",
    "target = train_data['Price']\n",
    "features = train_data.drop('Price', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03e9a867-1500-4fb4-879b-e123f6dcda2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating random forest object to fit the model to \n",
    "rfr = RandomForestRegressor( n_estimators = 100 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "968f5fba-4542-4cb6-9b05-179b13016571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the model \n",
    "rfr.fit(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dad42bf6-3c49-4885-8b11-b0fc76ab8b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_t_pred = rfr.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5b9104-e0cf-4615-a317-8be4e74ff464",
   "metadata": {},
   "source": [
    "# Creating Model - Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "360fd7cd-7fdd-426c-a8c7-a06a348e86e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# Create a decision tree classifier\n",
    "clf = DecisionTreeRegressor()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "588e677c-91a2-41ed-8f39-9140bd4cb443",
   "metadata": {},
   "outputs": [],
   "source": [
    "Decision_t_pred = clf.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b4a32a8-f1e2-4467-b282-4a7830803b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- np.array(target[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e1331-54c7-448f-8028-e7defa66981a",
   "metadata": {},
   "source": [
    "# Ensembling Models  - Decision Tree and Random Forest (Regressors)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5c9bcde-1b7f-4e28-be0d-fd4449757e09",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "new_predictions = []\n",
    "for i in range(len(list(rfr.predict(features)))):\n",
    "    #print('Ensemble:',  (list(rfr.predict(features))[i] + list(clf.predict(features))[i]) / 2)\n",
    "    new_predictions.append((list(rfr.predict(features))[i] + list(clf.predict(features))[i]) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18849cf9-f326-4243-9ae1-7bdb2e3edbf4",
   "metadata": {},
   "source": [
    "### Decision Tree seems to have the best metrics with the training data even after ensembling \n",
    "- Ensembling did improve the model we orginally had (rf regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c483574-6e12-492f-b82a-c62c4a4ebd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 24322.22186669215\n",
      "RSME: 155.95583306401898\n",
      "MAE: 68.28693048344712\n",
      "R2: 0.9489218198175037\n"
     ]
    }
   ],
   "source": [
    "#Ensemble Predictions error \n",
    "print(\"MSE:\", mean_squared_error(target, new_predictions))\n",
    "print(\"RSME:\", np.sqrt(mean_squared_error(target, new_predictions)))\n",
    "print(\"MAE:\", mean_absolute_error(target, new_predictions))\n",
    "print(\"R2:\", r2_score(target, new_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d97a323-ec6e-411e-af4b-f5d9e82c0d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 9053.472833969323\n",
      "RSME: 95.14973901156704\n",
      "MAE: 10.323616321949656\n",
      "R2: 0.9809871433939965\n"
     ]
    }
   ],
   "source": [
    "# Decsion Tree\n",
    "print(\"MSE:\", mean_squared_error(target, Decision_t_pred))\n",
    "print(\"RSME:\", np.sqrt(mean_squared_error(target, Decision_t_pred)))\n",
    "print(\"MAE:\", mean_absolute_error(target, Decision_t_pred))\n",
    "print(\"R2:\", r2_score(target, Decision_t_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d8119c7-e28d-4df1-9b31-b7a3f7c73b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 70128.46896486063\n",
      "RSME: 264.8178033381831\n",
      "MAE: 126.68048538105347\n",
      "R2: 0.8527258490880254\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "print(\"MSE:\", mean_squared_error(target, rf_t_pred))\n",
    "print(\"RSME:\", np.sqrt(mean_squared_error(target, rf_t_pred)))\n",
    "print(\"MAE:\", mean_absolute_error(target, rf_t_pred))\n",
    "print(\"R2:\", r2_score(target, rf_t_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc43e7f6-8292-473d-8ea7-b09df829375a",
   "metadata": {},
   "source": [
    "# Predicting the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d13d00-cde3-4ef9-9283-0bc3bd7d17d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4993aadf-bde6-496d-a9ed-48f69c9a20d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "efb60951-461b-4e75-9461-16d0251fe226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data\n",
    "a = cleaning(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c1e7f795-8bfe-4b10-a19f-e3da04dd8789",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = preprocessing(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c7582f43-39bf-4077-9686-92274b8b60a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tylerbrown/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- Author\n",
      "- BookCategory\n",
      "- Edition\n",
      "- Title\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- Edition_(French)\n",
      "- Edition_(German)\n",
      "- Edition_(Kannada)\n",
      "- Edition_(Spanish)\n",
      "- Edition_Board book\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'The Complete Sherlock Holmes: 2 Boxes sets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [96]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrfr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:971\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    969\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 971\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    974\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:579\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    578\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 579\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 566\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'The Complete Sherlock Holmes: 2 Boxes sets'"
     ]
    }
   ],
   "source": [
    "rfr.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9e9544c-66b9-4844-8a40-2b16b5c54745",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Price'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Price'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Price'"
     ]
    }
   ],
   "source": [
    "test_data['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8908f4aa-1817-40d3-96c2-6d5631fca2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a decision tree classifier\n",
    "clf = DecisionTreeRegressor()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(features,target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
